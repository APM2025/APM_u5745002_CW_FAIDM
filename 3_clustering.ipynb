{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Clustering — Model Building, Interpretation & Evaluation\n",
    "Following CRISP-DM Phases 4 (Modelling) and 5 (Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\nfrom sklearn.metrics import silhouette_score, silhouette_samples, davies_bouldin_score, adjusted_rand_score\nfrom sklearn.decomposition import PCA\nfrom scipy.stats import chi2_contingency\nimport scipy.cluster.hierarchy as sch\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Load pre-constructed clustering features\ndf = pd.read_csv('data/clustering_features_v3.csv')\n\n# Load target variable from raw dataset\ndf_raw = pd.read_csv('CDC Diabetes Dataset (4).csv')\ntarget = df_raw['Diabetes_012'].values\n\n# 6 features — cardio_metabolic_risk and bmi_category excluded after sensitivity\n# analysis showed removing them improves cluster quality while retaining diabetes separation\nfeatures = ['lifestyle_risk_score', 'limited_access_to_care', 'age_group',\n            'income_bracket', 'education_bracket', 'perceived_health_risk']\n\nprint(f\"Dataset: {df.shape[0]:,} records, {len(features)} features\")\nprint(f\"Target: {len(target):,} records\")\nprint(f\"\\nFeature ranges:\")\nfor col in features:\n    print(f\"  {col}: {df[col].min()}–{df[col].max()}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-technique",
   "metadata": {},
   "source": "## 4.1 Select Modelling Technique\n\n### Modelling Technique\n\nFour clustering algorithms are compared:\n\n| Algorithm | Distance Metric | Best For |\n|-----------|-----------------|----------|\n| K-Means | Euclidean | Continuous data, interpretable centroids |\n| Hierarchical (Ward) | Euclidean | Visualising cluster hierarchy |\n| DBSCAN | Euclidean | Density-based clusters, automatic k selection |\n| Hierarchical (Gower) | Gower | Mixed ordinal/binary data |\n\n**Primary choice: K-Means** — provides interpretable centroids describing the \"average patient\" in each segment, and a fixed number of clusters suitable for public health campaigns.\n\n### Modelling Assumptions\n\n| Assumption | K-Means Requires | Our Data | Mitigation |\n|------------|------------------|----------|------------|\n| Continuous features | Yes | Ordinal (0–4, 0–3, etc.) | Compare with Gower-distance clustering to validate |\n| Spherical clusters | Yes | Unknown | Check silhouette scores |\n| Similar scales | Yes | Different ranges | StandardScaler applied |\n| No missing values | Yes | None present | N/A |\n\n**Known limitation:** Features are ordinal, not truly continuous. K-Means treats the distance from 1→2 the same as 4→5, which may not reflect true dissimilarity. We validate by comparing with Gower-distance clustering — Gower distance is designed for mixed data types, using range-normalised Manhattan distance for ordinal features and simple matching for binary features.\n\n### Clustering Feature Set (6 features)\n\n| Feature | Type | Range | Domain |\n|---------|------|-------|--------|\n| lifestyle_risk_score | Ordinal | 0–4 | Behavioural |\n| limited_access_to_care | Binary | 0–1 | Access |\n| age_group | Ordinal | 0–3 | Demographic |\n| income_bracket | Ordinal | 0–2 | Socioeconomic |\n| education_bracket | Ordinal | 0–2 | Socioeconomic |\n| perceived_health_risk | Ordinal | 0–4 | Self-reported health |\n\nThis feature set spans **four domains** (behavioural, access/demographic, socioeconomic, self-reported health). Two clinical/anthropometric features were excluded after sensitivity analysis:\n- `cardio_metabolic_risk` (HighBP + HighChol) — degraded cluster quality without improving diabetes stratification\n- `bmi_category` — marginal contribution to diabetes separation; its removal improved silhouette and Davies-Bouldin scores\n\nThe retained features focus on **non-clinical dimensions** — behavioural choices, demographics, socioeconomic circumstances, and self-perceived health — making the segmentation more actionable for public health interventions that target modifiable risk factors and structural barriers."
  },
  {
   "cell_type": "markdown",
   "id": "cell-test-design",
   "metadata": {},
   "source": "## 4.2 Generate Test Design\n\nSince clustering is unsupervised (no ground truth labels), we use:\n\n**Internal validation metrics:**\n- **Silhouette Score** (−1 to 1): Measures cluster cohesion vs separation. Higher = better.\n- **Davies-Bouldin Index**: Ratio of within-cluster to between-cluster distance. Lower = better.\n- **Inertia**: Sum of squared distances to centroids (elbow method).\n\n**External validation:**\n- Compare cluster assignments across algorithms (Adjusted Rand Index)\n- Post-hoc validation against diabetes outcomes (not used for model selection — see Section 4.4.3)\n\n**Visualisation strategy:**\n- **PCA** (linear): For explained variance analysis, feature loadings interpretation, and cluster visualisation\n\n**Sampling strategy:**\n- 10% sample (≈25,368 records) for k-selection and algorithm comparison\n- Full dataset (253,680 records) for final model\n- Sampling required due to O(n²) complexity of silhouette calculation"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-preprocess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 253,680 records\n",
      "Sample (10%): 25,368 records\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing and sampling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df)\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_idx = np.random.choice(len(df), int(len(df) * 0.10), replace=False)\n",
    "X_sample = X_scaled[sample_idx]\n",
    "df_sample = df.iloc[sample_idx].copy()\n",
    "\n",
    "print(f\"Full dataset: {len(df):,} records\")\n",
    "print(f\"Sample (10%): {len(X_sample):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-k-heading",
   "metadata": {},
   "source": [
    "## 4.3 Build Model\n",
    "\n",
    "### 4.3.1 Parameter Settings — K Selection\n",
    "\n",
    "K is selected using **internal validation metrics only**. Diabetes outcomes are deliberately excluded from k-selection to avoid target leakage — using the outcome variable to tune hyperparameters would compromise the independence of the subsequent external validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-k-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate k=2 to 8 using internal metrics only\n",
    "k_range = range(2, 9)\n",
    "results = {'k': [], 'inertia': [], 'silhouette': [], 'davies_bouldin': []}\n",
    "\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_sample)\n",
    "    results['k'].append(k)\n",
    "    results['inertia'].append(km.inertia_)\n",
    "    results['silhouette'].append(silhouette_score(X_sample, labels))\n",
    "    results['davies_bouldin'].append(davies_bouldin_score(X_sample, labels))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-k-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise k-selection\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "axes[0].plot(k_range, results['inertia'], 'bo-')\n",
    "axes[0].set_xlabel('k'); axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method')\n",
    "\n",
    "axes[1].plot(k_range, results['silhouette'], 'go-')\n",
    "axes[1].set_xlabel('k'); axes[1].set_ylabel('Silhouette')\n",
    "axes[1].set_title('Silhouette (higher=better)')\n",
    "\n",
    "axes[2].plot(k_range, results['davies_bouldin'], 'ro-')\n",
    "axes[2].set_xlabel('k'); axes[2].set_ylabel('Davies-Bouldin')\n",
    "axes[2].set_title('Davies-Bouldin (lower=better)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/k_selection.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dendro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendrogram for hierarchical perspective\n",
    "dendro_idx = np.random.choice(len(X_sample), 1000, replace=False)\n",
    "linkage_matrix = sch.linkage(X_sample[dendro_idx], method='ward')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sch.dendrogram(linkage_matrix, ax=ax, no_labels=True, color_threshold=20)\n",
    "ax.set_title('Dendrogram (Ward Linkage)')\n",
    "ax.set_ylabel('Distance')\n",
    "ax.axhline(y=20, color='r', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/dendrogram.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-k-decision",
   "metadata": {},
   "source": [
    "### Parameter Settings Decision\n",
    "\n",
    "**Selected: k=3**\n",
    "\n",
    "| Criterion | Observation |\n",
    "|-----------|-------------|\n",
    "| Elbow | Visible bend around k=3 |\n",
    "| Silhouette | k=3 offers good trade-off between cluster quality and interpretability |\n",
    "| Davies-Bouldin | k=3 shows acceptable cluster separation |\n",
    "| Dendrogram | Cutting at distance ≈20 suggests 3 clusters |\n",
    "| Interpretability | 3 segments are manageable for public health campaigns |\n",
    "\n",
    "**K-Means parameters:** `n_clusters=3`, `n_init=10`, `random_state=42`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-model-heading",
   "metadata": {},
   "source": [
    "### 4.3.2 Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-final-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_K = 3\n",
    "\n",
    "final_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('kmeans', KMeans(n_clusters=CHOSEN_K, random_state=42, n_init=10))\n",
    "])\n",
    "\n",
    "# Fit on features only (not extra columns that may have been added)\n",
    "df['cluster'] = final_model.fit_predict(df[features])\n",
    "\n",
    "print(f\"Final model fitted on {len(df):,} records\")\n",
    "print(f\"\\nCluster sizes:\")\n",
    "for c in range(CHOSEN_K):\n",
    "    n = (df['cluster'] == c).sum()\n",
    "    print(f\"  Cluster {c}: {n:,} ({n/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-centroids",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centroids (inverse-transformed for interpretation)\n",
    "kmeans_model = final_model.named_steps['kmeans']\n",
    "scaler_model = final_model.named_steps['scaler']\n",
    "centroids_scaled = kmeans_model.cluster_centers_\n",
    "centroids = scaler_model.inverse_transform(centroids_scaled)\n",
    "\n",
    "centroids_df = pd.DataFrame(centroids, columns=features)\n",
    "centroids_df.index.name = 'Cluster'\n",
    "print(\"Cluster centroids (mean feature values):\")\n",
    "print(centroids_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-model-desc",
   "metadata": {},
   "source": "### Model Description\n\nThe K-Means model partitions 253,680 patients into 3 segments based on 6 non-clinical features:\n- Lifestyle risk score (0–4)\n- Healthcare access barriers (0–1)\n- Age group (0–3)\n- Income bracket (0–2)\n- Education bracket (0–2)\n- Perceived health risk (0–4)\n\nClinical and anthropometric features (`cardio_metabolic_risk`, `bmi_category`) were excluded based on sensitivity analysis — they degraded cluster quality without meaningfully improving diabetes stratification.\n\nCentroids represent the \"average patient\" in each cluster — interpretable for designing targeted interventions."
  },
  {
   "cell_type": "markdown",
   "id": "cell-assess-heading",
   "metadata": {},
   "source": [
    "## 4.4 Assess Model\n",
    "\n",
    "### 4.4.1 Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-algo-compare",
   "metadata": {},
   "outputs": [],
   "source": "# Compare algorithms on 10% sample\nkm_labels = KMeans(n_clusters=CHOSEN_K, random_state=42, n_init=10).fit_predict(X_sample)\nhier_labels = AgglomerativeClustering(n_clusters=CHOSEN_K, linkage='ward').fit_predict(X_sample)\n\n# DBSCAN - auto-determines clusters based on density\ndbscan = DBSCAN(eps=2.0, min_samples=50)\ndbscan_labels = dbscan.fit_predict(X_sample)\nn_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\nn_noise = list(dbscan_labels).count(-1)\n\n# Gower distance — appropriate for mixed ordinal/binary features\n# Uses range-normalised Manhattan distance for ordinal, simple matching for binary\n# Computed on a 5,000-point subsample (O(n²) distance matrix)\nnp.random.seed(42)\ngower_idx = np.random.choice(len(X_sample), 5000, replace=False)\nX_gower_raw = df_sample[features].values[gower_idx]\n\n# Ranges: lifestyle=4, access=0(binary), age=3, income=2, education=2, perceived=4\nfeature_ranges = np.array([4, 0, 3, 2, 2, 4], dtype=float)  # 0 = binary\nn_gower = X_gower_raw.shape[0]\nn_feat = X_gower_raw.shape[1]\nD_gower = np.zeros((n_gower, n_gower))\nfor j in range(n_feat):\n    col = X_gower_raw[:, j:j+1]\n    if feature_ranges[j] == 0:  # binary feature\n        D_gower += (col != col.T).astype(float)\n    else:  # ordinal feature\n        D_gower += np.abs(col - col.T) / feature_ranges[j]\nD_gower /= n_feat\n\ngower_hier = AgglomerativeClustering(n_clusters=CHOSEN_K, metric='precomputed', linkage='average')\ngower_labels = gower_hier.fit_predict(D_gower)\n\n# Get K-Means labels on same subsample for fair comparison\nkm_labels_sub = km_labels[gower_idx]\n\ncomparison = {\n    'Algorithm': ['K-Means', 'Hierarchical (Ward)', 'DBSCAN', 'Hierarchical (Gower)'],\n    'Silhouette': [\n        silhouette_score(X_sample, km_labels),\n        silhouette_score(X_sample, hier_labels),\n        silhouette_score(X_sample, dbscan_labels) if n_clusters_dbscan > 1 else 0.0,\n        silhouette_score(D_gower, gower_labels, metric='precomputed')\n    ],\n    'Davies-Bouldin': [\n        davies_bouldin_score(X_sample, km_labels),\n        davies_bouldin_score(X_sample, hier_labels),\n        davies_bouldin_score(X_sample, dbscan_labels) if n_clusters_dbscan > 1 else np.nan,\n        davies_bouldin_score(X_gower_raw, gower_labels)\n    ],\n    'N_Clusters': [CHOSEN_K, CHOSEN_K, n_clusters_dbscan, CHOSEN_K]\n}\n\nprint(f\"DBSCAN found {n_clusters_dbscan} clusters and {n_noise} noise points ({n_noise/len(X_sample)*100:.1f}%)\")\nprint(f\"Gower distance computed on {n_gower:,}-point subsample\")\nprint()\nprint(pd.DataFrame(comparison).round(4).to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ari",
   "metadata": {},
   "outputs": [],
   "source": "# Algorithm agreement (Adjusted Rand Index)\nprint(\"Algorithm Agreement (ARI):\")\nprint(f\"  K-Means vs Hierarchical (Ward): {adjusted_rand_score(km_labels, hier_labels):.3f}\")\nprint(f\"  K-Means vs DBSCAN:              {adjusted_rand_score(km_labels, dbscan_labels):.3f}\")\nprint(f\"  K-Means vs Gower (subsample):   {adjusted_rand_score(km_labels_sub, gower_labels):.3f}\")\n\nprint(f\"\\nNote: Gower comparison uses a 5,000-point subsample (O(n²) distance matrix)\")\nprint(f\"DBSCAN uses density-based clustering — low agreement is expected if natural structure differs from k={CHOSEN_K}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-algo-findings",
   "metadata": {},
   "source": "**Algorithm comparison findings:**\n\n- **K-Means** produces well-defined clusters with interpretable centroids\n- **Hierarchical (Ward)** clustering shows moderate agreement with K-Means, confirming the cluster structure is not purely an artefact of the algorithm\n- **DBSCAN** automatically identifies clusters based on density — if it finds a very different number of clusters or many noise points, this suggests the k=3 structure may be imposed rather than natural\n- **Hierarchical (Gower)** uses Gower distance, which is appropriate for mixed ordinal/binary data. It applies range-normalised Manhattan distance for ordinal features and simple matching for binary features, avoiding the assumption that ordinal categories are equally spaced. Agreement with K-Means validates that the cluster structure is robust to the choice of distance metric\n- **Conclusion:** K-Means is retained for its combination of cluster quality, centroid interpretability (\"average patient\" profiles), and suitability for creating a fixed number of actionable patient segments for public health campaigns. The Gower-distance comparison confirms the structure holds under an ordinal-appropriate metric"
  },
  {
   "cell_type": "markdown",
   "id": "cell-internal-heading",
   "metadata": {},
   "source": [
    "### 4.4.2 Internal Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-silhouette-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette analysis on 10% sample\n",
    "X_scaled_full = final_model.named_steps['scaler'].transform(df[features])\n",
    "X_eval = X_scaled_full[sample_idx]\n",
    "labels_eval = df['cluster'].values[sample_idx]\n",
    "\n",
    "sil_avg = silhouette_score(X_eval, labels_eval)\n",
    "sil_samples = silhouette_samples(X_eval, labels_eval)\n",
    "db_score = davies_bouldin_score(X_eval, labels_eval)\n",
    "\n",
    "print(f\"Overall Metrics (10% sample, n={len(sample_idx):,}):\")\n",
    "print(f\"  Silhouette Score: {sil_avg:.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {db_score:.4f}\")\n",
    "\n",
    "print(f\"\\nPer-cluster Silhouette:\")\n",
    "for c in range(CHOSEN_K):\n",
    "    cluster_sil = sil_samples[labels_eval == c].mean()\n",
    "    n = (labels_eval == c).sum()\n",
    "    print(f\"  Cluster {c}: {cluster_sil:.4f} (n={n:,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-silhouette-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "y_lower = 10\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, CHOSEN_K))\n",
    "\n",
    "for i in range(CHOSEN_K):\n",
    "    cluster_sil = sil_samples[labels_eval == i]\n",
    "    cluster_sil.sort()\n",
    "    y_upper = y_lower + len(cluster_sil)\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_sil,\n",
    "                     alpha=0.7, color=colors[i])\n",
    "    ax.text(-0.05, y_lower + 0.5 * len(cluster_sil), str(i))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax.axvline(x=sil_avg, color='red', linestyle='--', label=f'Average: {sil_avg:.3f}')\n",
    "ax.set_xlabel('Silhouette Coefficient')\n",
    "ax.set_ylabel('Cluster')\n",
    "ax.set_title('Silhouette Plot (10% sample)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/silhouette_plot.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-internal-interp",
   "metadata": {},
   "source": [
    "**Internal validation interpretation:**\n",
    "\n",
    "| Metric | Value | Interpretation |\n",
    "|--------|-------|----------------|\n",
    "| Silhouette | *See output above* | Within typical range (0.20–0.50) for real-world data with ordinal features |\n",
    "| Davies-Bouldin | *See output above* | Lower is better; <1.5 is acceptable |\n",
    "\n",
    "The silhouette plot shows:\n",
    "- All clusters should have positive average silhouette (no systematically misassigned cluster)\n",
    "- Width of each \"blade\" indicates cluster size\n",
    "- Points extending past the red dashed line (average silhouette) are well-clustered; points near zero are borderline\n",
    "- Any cluster with consistently low silhouette values indicates more overlap with other clusters\n",
    "\n",
    "**Conclusion:** The clustering has acceptable internal validity — clusters are cohesive and reasonably well-separated given the ordinal nature of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-external-heading",
   "metadata": {},
   "source": "### 4.4.3 External Validation: Diabetes Outcomes\n\nSince diabetes status was **not used** in clustering, different diabetes rates across clusters would suggest that our segmentation captures health-relevant patterns.\n\n**Important caveat:** `perceived_health_risk` (GenHlth + DiffWalk + PhysHlth, ρ ≈ 0.35) is a known diabetes correlate. Clusters that differ in this feature will *mechanistically* differ in diabetes rates. However, the remaining 5 features (lifestyle, access, age, income, education) are associated with diabetes through **indirect pathways** (behavioural, demographic, structural), making their contribution to cluster separation more genuinely external.\n\nThis external validation is best interpreted as a **consistency check** rather than independent evidence of predictive power."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-profiles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster profiles\n",
    "profiles = df.groupby('cluster')[features].mean()\n",
    "profiles['n'] = df.groupby('cluster').size()\n",
    "profiles['%'] = (profiles['n'] / len(df) * 100).round(1)\n",
    "\n",
    "print(\"Cluster Profiles (mean feature values):\")\n",
    "print(profiles.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "im = ax.imshow(profiles[features].values, cmap='YlOrRd', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(features)))\n",
    "ax.set_yticks(range(len(profiles)))\n",
    "ax.set_xticklabels(features, rotation=45, ha='right')\n",
    "ax.set_yticklabels([f'Cluster {i}' for i in profiles.index])\n",
    "\n",
    "for i in range(len(profiles)):\n",
    "    for j in range(len(features)):\n",
    "        val = profiles[features].iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.2f}', ha='center', va='center',\n",
    "                color='white' if val > profiles[features].values.max()/2 else 'black')\n",
    "\n",
    "plt.colorbar(im, label='Mean Value')\n",
    "ax.set_title('Cluster Profiles')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/cluster_profiles.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-diabetes-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes rates by cluster\n",
    "df['Diabetes_012'] = target\n",
    "diabetes_rates = pd.crosstab(df['cluster'], df['Diabetes_012'], normalize='index')\n",
    "diabetes_rates.columns = ['No Diabetes', 'Prediabetes', 'Diabetes']\n",
    "\n",
    "print(\"Diabetes prevalence by cluster:\")\n",
    "print(diabetes_rates.round(3))\n",
    "\n",
    "print(f\"\\nDiabetes rate range: {diabetes_rates['Diabetes'].min()*100:.1f}% to {diabetes_rates['Diabetes'].max()*100:.1f}%\")\n",
    "print(f\"Spread: {(diabetes_rates['Diabetes'].max() - diabetes_rates['Diabetes'].min())*100:.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-diabetes-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "diabetes_rates.plot(kind='bar', ax=ax, color=['#2ecc71', '#f39c12', '#e74c3c'])\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.set_title('Diabetes Prevalence by Cluster')\n",
    "ax.set_xticklabels([f'Cluster {i}' for i in diabetes_rates.index], rotation=0)\n",
    "ax.legend(title='Status')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/diabetes_by_cluster.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-chi2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "contingency = pd.crosstab(df['cluster'], df['Diabetes_012'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "print(f\"Chi-square test for independence:\")\n",
    "print(f\"  Chi-sq = {chi2:.2f}\")\n",
    "print(f\"  df = {dof}\")\n",
    "print(f\"  p-value = {p_value:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-external-interp",
   "metadata": {},
   "source": "**External validation interpretation:**\n\nThe chi-square test is highly significant (p < 0.001), confirming that cluster membership and diabetes status are **not independent**.\n\nHowever, this result must be interpreted with caution:\n\n1. **One feature is a direct diabetes correlate.** `perceived_health_risk` (GenHlth, DiffWalk, PhysHlth) is the strongest individual predictor of diabetes in the dataset. Clusters that differ in this feature will *mechanistically* show different diabetes rates.\n\n2. **The remaining 5 features contribute through indirect pathways.** Lifestyle risk, age, SES, and healthcare access are associated with diabetes through behavioural, demographic, and structural mechanisms — their contribution to diabetes separation is more genuinely \"external\" and not circular.\n\n3. **The validation is stronger than with clinical markers.** Unlike the 8-feature model (which included `cardio_metabolic_risk` and `bmi_category`), this 6-feature model has only one direct diabetes correlate, making the external validation less circular.\n\n**Public health implication:** The clusters identify distinct patient subgroups based primarily on modifiable risk factors (lifestyle, access) and socioeconomic circumstances, making them directly actionable for public health campaigns."
  },
  {
   "cell_type": "markdown",
   "id": "ompe08m4eak",
   "metadata": {},
   "source": "### 4.4.4 Sensitivity Analysis: Effect of Clinical/Anthropometric Features\n\nTo justify the 6-feature model, we compare cluster quality and diabetes stratification across three feature sets — progressively adding clinical and anthropometric features to show their effect on the trade-off between cluster quality and diabetes separation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcjpfywyq4",
   "metadata": {},
   "outputs": [],
   "source": "# Compare 6 vs 7 vs 8 feature models\nfeatures_7 = features + ['bmi_category']\nfeatures_8 = features + ['bmi_category', 'cardio_metabolic_risk']\n\nprint(f\"6 features: {features}\")\nprint(f\"7 features: {features_7}  (+bmi_category)\")\nprint(f\"8 features: {features_8}  (+bmi_category, +cardio_metabolic_risk)\")\n\n# --- 7-feature model ---\nmodel_7 = Pipeline([('scaler', StandardScaler()),\n                     ('kmeans', KMeans(n_clusters=CHOSEN_K, random_state=42, n_init=10))])\nlabels_7 = model_7.fit_predict(df[features_7])\n\nX_7_eval = model_7.named_steps['scaler'].transform(df[features_7])[sample_idx]\nlabels_7_eval = labels_7[sample_idx]\nsil_7 = silhouette_score(X_7_eval, labels_7_eval)\ndb_7 = davies_bouldin_score(X_7_eval, labels_7_eval)\n\nrates_7 = pd.crosstab(pd.Series(labels_7), pd.Series(target), normalize='index')\nrates_7.columns = ['No Diabetes', 'Prediabetes', 'Diabetes']\nspread_7 = (rates_7['Diabetes'].max() - rates_7['Diabetes'].min()) * 100\nchi2_7, _, _, _ = chi2_contingency(pd.crosstab(pd.Series(labels_7), pd.Series(target)))\n\n# --- 8-feature model ---\nmodel_8 = Pipeline([('scaler', StandardScaler()),\n                     ('kmeans', KMeans(n_clusters=CHOSEN_K, random_state=42, n_init=10))])\nlabels_8 = model_8.fit_predict(df[features_8])\n\nX_8_eval = model_8.named_steps['scaler'].transform(df[features_8])[sample_idx]\nlabels_8_eval = labels_8[sample_idx]\nsil_8 = silhouette_score(X_8_eval, labels_8_eval)\ndb_8 = davies_bouldin_score(X_8_eval, labels_8_eval)\n\nrates_8 = pd.crosstab(pd.Series(labels_8), pd.Series(target), normalize='index')\nrates_8.columns = ['No Diabetes', 'Prediabetes', 'Diabetes']\nspread_8 = (rates_8['Diabetes'].max() - rates_8['Diabetes'].min()) * 100\nchi2_8, _, _, _ = chi2_contingency(pd.crosstab(pd.Series(labels_8), pd.Series(target)))\n\n# --- Side-by-side comparison ---\nspread_full = (diabetes_rates['Diabetes'].max() - diabetes_rates['Diabetes'].min()) * 100\n\nprint(f\"\\n{'Metric':<25} {'6 features':>12} {'7 (+BMI)':>12} {'8 (+both)':>12}\")\nprint(\"-\" * 61)\nprint(f\"{'Silhouette ↑':<25} {sil_avg:>12.3f} {sil_7:>12.3f} {sil_8:>12.3f}\")\nprint(f\"{'Davies-Bouldin ↓':<25} {db_score:>12.3f} {db_7:>12.3f} {db_8:>12.3f}\")\nprint(f\"{'Diabetes spread (pp)':<25} {spread_full:>11.1f}pp {spread_7:>11.1f}pp {spread_8:>11.1f}pp\")\nprint(f\"{'Chi-square':<25} {chi2:>12,.0f} {chi2_7:>12,.0f} {chi2_8:>12,.0f}\")\n\nprint(f\"\\n--- Per-cluster diabetes prevalence ---\")\nprint(f\"\\n6 features (selected model):\")\nprint(diabetes_rates.round(3))\nprint(f\"\\n7 features (+bmi_category):\")\nprint(rates_7.round(3))\nprint(f\"\\n8 features (+bmi_category, +cardio_metabolic_risk):\")\nprint(rates_8.round(3))"
  },
  {
   "cell_type": "markdown",
   "id": "s020y5y3jm",
   "metadata": {},
   "source": "**Sensitivity analysis findings:**\n\nThree feature sets are compared to evaluate the trade-off between cluster quality and diabetes stratification:\n\n| Feature Set | Added Features | Effect |\n|-------------|---------------|--------|\n| 6 features | — (selected model) | Best cluster quality |\n| 7 features | + `bmi_category` | Slight diabetes improvement, cluster quality drops |\n| 8 features | + `bmi_category`, `cardio_metabolic_risk` | Most diabetes separation, worst cluster quality |\n\nKey observations:\n\n1. **Adding clinical/anthropometric features increases diabetes separation** — the chi-square and diabetes spread both rise with 7 and 8 features, confirming that `bmi_category` and `cardio_metabolic_risk` carry genuine diabetes-related signal\n\n2. **But cluster quality degrades substantially** — silhouette drops and Davies-Bouldin rises with each additional feature. The clinical features fragment the cluster structure without forming tighter groups, because they introduce noise into the distance calculations\n\n3. **The diabetes separation gains are marginal relative to the quality loss** — the 6-feature model already achieves meaningful diabetes stratification across clusters. The additional features provide diminishing returns: a modest increase in spread at a disproportionate cost to cluster cohesion\n\n4. **The 6-feature model offers the best trade-off** — it produces the most geometrically cohesive clusters while retaining sufficient diabetes separation for public health relevance. The clusters are defined by actionable, non-clinical dimensions (behaviour, demographics, SES, perceived health), which are more useful for designing targeted interventions than clinical measurements that patients cannot easily modify"
  },
  {
   "cell_type": "markdown",
   "id": "cell-pca-heading",
   "metadata": {},
   "source": "### 4.4.5 Dimensionality Reduction Visualisation\n\n**PCA** (linear) is used to visualise the cluster structure in 2D:\n- Preserves global variance structure\n- Interpretable loadings show which features drive each axis\n- Scree plot shows how variance is distributed across components"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with all components for scree plot\n",
    "pca_full = PCA(random_state=42)\n",
    "pca_full.fit(X_scaled_full)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled_full)\n",
    "\n",
    "print(f\"Variance explained:\")\n",
    "for i, var in enumerate(pca_full.explained_variance_ratio_):\n",
    "    print(f\"  PC{i+1}: {var:.1%}\")\n",
    "print(f\"  Total (2 components): {sum(pca.explained_variance_ratio_):.1%}\")\n",
    "\n",
    "# Scree plot\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "cumulative = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "ax.bar(range(1, len(pca_full.explained_variance_ratio_)+1), \n",
    "       pca_full.explained_variance_ratio_, alpha=0.7, label='Individual')\n",
    "ax.plot(range(1, len(cumulative)+1), cumulative, 'ro-', label='Cumulative')\n",
    "ax.set_xlabel('Principal Component')\n",
    "ax.set_ylabel('Variance Explained')\n",
    "ax.set_title('PCA Scree Plot')\n",
    "ax.legend()\n",
    "ax.set_xticks(range(1, len(pca_full.explained_variance_ratio_)+1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/pca_scree.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pca-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample for clean visualisation\n",
    "np.random.seed(42)\n",
    "plot_idx = np.random.choice(len(df), 2000, replace=False)\n",
    "X_pca_plot = X_pca[plot_idx]\n",
    "labels_plot = df['cluster'].values[plot_idx]\n",
    "diabetes_plot = df['Diabetes_012'].values[plot_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Clusters in PCA space\n",
    "cmap = plt.cm.viridis(np.linspace(0, 0.95, CHOSEN_K))\n",
    "for c in range(CHOSEN_K):\n",
    "    mask = labels_plot == c\n",
    "    axes[0].scatter(X_pca_plot[mask, 0], X_pca_plot[mask, 1],\n",
    "                    s=20, alpha=0.5, color=cmap[c], label=f'Cluster {c}',\n",
    "                    edgecolors='none')\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "axes[0].set_title('Clusters in PCA Space')\n",
    "axes[0].legend(markerscale=2)\n",
    "\n",
    "# Diabetes status in PCA space\n",
    "colors_diab = {0: '#59a14f', 1: '#edc948', 2: '#e15759'}\n",
    "names_diab = {0: 'No Diabetes', 1: 'Prediabetes', 2: 'Diabetes'}\n",
    "for status in [0, 1, 2]:\n",
    "    mask = diabetes_plot == status\n",
    "    axes[1].scatter(X_pca_plot[mask, 0], X_pca_plot[mask, 1],\n",
    "                    s=20, alpha=0.5, color=colors_diab[status],\n",
    "                    label=names_diab[status], edgecolors='none')\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "axes[1].set_title('Diabetes Status in PCA Space')\n",
    "axes[1].legend(markerscale=2)\n",
    "\n",
    "# PCA biplot — feature loading arrows\n",
    "loadings = pca.components_.T\n",
    "for i, feat in enumerate(features):\n",
    "    axes[2].arrow(0, 0, loadings[i, 0]*3, loadings[i, 1]*3,\n",
    "                  head_width=0.08, head_length=0.05, fc='steelblue', ec='steelblue')\n",
    "    axes[2].text(loadings[i, 0]*3.3, loadings[i, 1]*3.3, feat,\n",
    "                 fontsize=8, ha='center', va='center')\n",
    "axes[2].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[2].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "axes[2].set_title('PCA Biplot (Feature Loadings)')\n",
    "axes[2].axhline(0, color='grey', linewidth=0.5)\n",
    "axes[2].axvline(0, color='grey', linewidth=0.5)\n",
    "axes[2].set_xlim(-1.5, 1.5)\n",
    "axes[2].set_ylim(-1.5, 1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/pca_combined.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pca-loadings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature loadings\n",
    "loadings_df = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2'], index=features)\n",
    "print(\"PCA Feature Loadings:\")\n",
    "print(loadings_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-pca-interp",
   "metadata": {},
   "source": "**PCA interpretation:**\n\nWith 6 features, the first two principal components capture a moderate proportion of total variance (see scree plot above). The remaining variance is distributed across higher dimensions that cannot be visualised in 2D.\n\n**Reading the loadings (biplot):**\n\nThe feature loadings and biplot show which features drive each principal component:\n\n- **PC1** is typically driven by perceived health risk and lifestyle risk score vs. socioeconomic status (income, education)\n  - Interpretation: High-risk health/lifestyle profile vs. high-SES healthy profile\n\n- **PC2** typically contrasts age/demographic features vs. lifestyle and access barriers\n  - Interpretation: Older patients with health concerns vs. younger patients with lifestyle risks\n\n**Key takeaway:** PCA provides interpretable axes (via loadings) that confirm the clusters capture genuine structure across the 6-dimensional feature space. Some overlap between clusters in 2D is expected because the first two components do not capture all variance — the clusters may be better separated in the full 6D space."
  },
  {
   "cell_type": "markdown",
   "id": "cell-eval-heading",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "### 5.1 Cluster Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-interpretation",
   "metadata": {},
   "outputs": [],
   "source": "# Detailed cluster summary\nprint(\"=\" * 70)\nprint(\"CLUSTER INTERPRETATION\")\nprint(\"=\" * 70)\n\nfor c in range(CHOSEN_K):\n    p = profiles.loc[c]\n    cluster_df = df[df['cluster'] == c]\n    diabetes_rate = (cluster_df['Diabetes_012'] == 2).mean() * 100\n    prediabetes_rate = (cluster_df['Diabetes_012'] == 1).mean() * 100\n\n    risk_level = \"High\" if p['lifestyle_risk_score'] > 2.0 else \"Moderate\" if p['lifestyle_risk_score'] > 1.0 else \"Low\"\n    access_issue = \"Yes\" if p['limited_access_to_care'] > 0.5 else \"No\"\n    age_cat = [\"Young\", \"Middle\", \"Older\", \"Elderly\"][min(int(round(p['age_group'])), 3)]\n    ses = \"High\" if (p['income_bracket'] + p['education_bracket']) > 3 else \\\n          \"Low\" if (p['income_bracket'] + p['education_bracket']) < 2 else \"Medium\"\n    health_perc = \"Poor\" if p['perceived_health_risk'] > 2.0 else \"Fair\" if p['perceived_health_risk'] > 1.0 else \"Good\"\n\n    print(f\"\\nCLUSTER {c}\")\n    print(f\"  Size: {p['n']:,.0f} ({p['%']:.1f}%)\")\n    print(f\"  Lifestyle risk: {p['lifestyle_risk_score']:.2f}/4 ({risk_level})\")\n    print(f\"  Perceived health: {p['perceived_health_risk']:.2f}/4 ({health_perc})\")\n    print(f\"  Access barrier: {p['limited_access_to_care']:.1%} ({access_issue})\")\n    print(f\"  Age: {p['age_group']:.1f} ({age_cat})\")\n    print(f\"  SES: Income={p['income_bracket']:.1f}, Education={p['education_bracket']:.1f} ({ses})\")\n    print(f\"  Diabetes: {diabetes_rate:.1f}%, Prediabetes: {prediabetes_rate:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-labels",
   "metadata": {},
   "source": "### 5.2 Cluster Labels and Intervention Strategy\n\nBased on the cluster profiles above, three distinct patient segments emerge. Review the cluster interpretation output and diabetes prevalence table to complete the characterization:\n\n| Cluster | Label | Key Characteristics | Diabetes Rate | Size | Priority | Intervention Strategy |\n|---------|-------|---------------------|---------------|------|----------|----------------------|\n| **0** | *[Label based on output]* | *[Review cluster interpretation]* | *[See output]* | *[%]* | *[Priority]* | *[Tailored intervention based on risk profile]* |\n| **1** | *[Label based on output]* | *[Review cluster interpretation]* | *[See output]* | *[%]* | *[Priority]* | *[Tailored intervention based on risk profile]* |\n| **2** | *[Label based on output]* | *[Review cluster interpretation]* | *[See output]* | *[%]* | *[Priority]* | *[Tailored intervention based on risk profile]* |\n\n**Instructions:** After running all cells, fill in this table based on:\n- Cluster interpretation output (Section 5.1)\n- Diabetes prevalence by cluster\n- Centroid values showing mean feature levels\n\n**Key considerations for public health planning:**\n\n- Identify the highest-risk cluster (highest diabetes rate, perceived health risk) for priority intervention\n- Design cluster-specific interventions addressing their unique combination of risk factors\n- Distinguish between behavioural risk, perceived health, socioeconomic status, and access barriers\n- Consider both cluster size and risk level when allocating resources"
  },
  {
   "cell_type": "markdown",
   "id": "cell-limitations",
   "metadata": {},
   "source": "### 5.3 Limitations and Ethical Considerations\n\n**Methodological limitations:**\n- Ordinal features treated as continuous (K-Means assumption violated; validated against Gower-distance clustering and DBSCAN)\n- Cross-sectional data — cannot infer causal relationships between cluster membership and diabetes\n- Self-reported data may have recall and social desirability bias\n- `perceived_health_risk` is a known diabetes correlate, so external validation against diabetes outcomes is partly circular (though only 1 of 6 features, unlike the original 8-feature model)\n- Silhouette score is moderate, indicating some overlap between clusters — boundaries are not sharp\n\n**Ethical considerations:**\n- Risk of stigmatisation if clusters are labelled negatively\n- Interventions should empower, not blame patients\n- SES-based targeting could reinforce existing inequalities if not implemented carefully\n- Need to ensure equitable resource allocation across all clusters"
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": "## Summary\n\n| CRISP-DM Phase | Finding |\n|----------------|--------|\n| 4.1 Select Technique | K-Means (primary), Hierarchical (Ward), DBSCAN & Hierarchical (Gower) (validation) |\n| 4.2 Test Design | Silhouette, DB, ARI (internal); diabetes prevalence (external, post-hoc); PCA (visualisation) |\n| 4.3 Build Model | k=3, n_init=10, StandardScaler, 6 non-clinical features |\n| 4.4 Assess Model | Acceptable internal metrics; significant diabetes separation (with caveats); PCA confirms cluster structure |\n| 5. Evaluation | 3 interpretable segments combining behavioural, self-reported health, socioeconomic, and demographic dimensions |\n\n**Key methodological decisions:**\n- K selected using **internal metrics only** to avoid target leakage\n- Clinical/anthropometric features (`cardio_metabolic_risk`, `bmi_category`) excluded after sensitivity analysis showed they degraded cluster quality without improving diabetes stratification\n- 6-feature model focuses on **non-clinical, actionable dimensions** — modifiable behaviours, demographics, SES, access, and self-perceived health\n- External validation against diabetes is less circular than the original 8-feature model (only 1 of 6 features is a direct diabetes correlate)\n- K-Means chosen over alternatives (Hierarchical, DBSCAN, Gower-distance clustering) for centroid interpretability and fixed segment count\n- Gower distance used for validation — handles mixed ordinal/binary data without assuming equal spacing"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}